# Lab of Selected Themes on Computer Linguistics 2025-2

Repositorio para las pr√°cticas de la materia Temas Selectos de Ling√º√≠stica
Computacional en la Lic. de Ciencias de Datos, IIMAS, UNAM

## Instalaci√≥n de dependencias

Usaremos `uv` como gestor de dependencias.

- [Instalaci√≥n del programa](https://docs.astral.sh/uv/getting-started/installation/)

Una ves instalado basta con ejecutar el siguiente comando para levantar jupyter lab local con las dependencias:

```shell
$ uv run jupyter-lab
```

Si precisas instalar alguna dependencia puedes agregarla con:

```shell
$ uv add <dep>
```

**Toma en cuenta que si agregas dependencias estas se agregar√° al repositorio
principal (`pyproject.toml` y `uv.lock`) con tu PR asi que cuida lo que
precises instalar**

# Pr√°cticas

### Lineamientos generales

- Es muy recomendable entregar las pr√°cticas ya que representa un porcentaje
importante de su calificaci√≥n (40%) ü§ì
- Se dar√° ~2 semanas para entregar ejercicios (dependiendo de la pr√°ctica)
    - En caso de **entregas tard√≠as** abr√° una penalizaci√≥n `-1 punto` por cada d√≠a
- Si utilizas LLMs, o herramientas generativas reportalos en tus pr√°cticas üßô
  - Les recomendamos ampliamente que lo intenten por su cuenta primero, es una
  oportunidad de enfrentarse a cosas nuevas y de pensar en soluciones por su
  cuenta :)

## 0. Creaci√≥n de carpeta personal via *Pull Request (PR)*

Crear un PR con lo siguiente:

- Una carpeta con su username de GitHub dentro de `practicas/` y otra carpeta interna llamada `P0/`
    - `practicas/umoqnier/P0`
- Agrega un archivo llamado `README.md` a la carpeta `P0/` con informaci√≥n b√°sica sobre t√≠. Ejemplo:
    - `practices/umoqnier/P0/README.md`
    - Usar lenguaje de marcado [Markdown](https://docs.github.com/es/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)

```markdown
$ cat README.md

# Diego Alberto Barriga Mart√≠nez

- N√∫mero de cuenta: `XXXXXXXX`
- User de Github: @umoqnier
- Me gusta que me llamen: Dieguito

## Pasatiempos

- Andar en bici

## Proyectos en los que he participado y que me enorgullesen üñ§

- [Esquite](https://github.com/ElotlMX/Esquite/)
```

## 1. Niveles Ling√º√≠sticos

### FECHA DE ENTREGA: 16 de Febrero 2025 at 11:59pm

### Fon√©tica

1. Si tenemos un sistema de b√∫squeda que recibe una palabra ortogr√°fica y devuelve sus transcripciones fonol√≥gicas, proponga una soluci√≥n para los casos en que la palabra buscada no se encuentra en el lexic√≥n/diccionario. *¬øC√≥mo devolver o aproximar su transcripci√≥n fonol√≥gica?*
  - Reutiliza el sistema de b√∫squeda visto en clase y mejoralo con esta funcionalidad

### Morfolog√≠a

2. Obtenga los datos de `test` y `dev` para todas las lenguas disponibles en el Shared Task SIGMORPHON 2022 y haga lo siguiente:
    - En un plot de 4 columnas y 2 rows muestre las siguientes distribuciones (un subplot por lengua):
        - Plot 1: distribuci√≥n de longitud de palabras
        - Plot 2: distribuci√≥n de la cuenta de morfemas
        - Plot 3: distribuci√≥n de categorias (si existe para la lengua)
    - Realice una funci√≥n que imprima por cada lengua lo siguiente:
        - Total de palabras
        - La longitud de palabra promedio
        - La cuenta de morfemas promedio
        - La categor√≠a m√°s com√∫n
    - Con base en esta informaci√≥n elabore una conclusi√≥n ling√º√≠stica sobre la morfolog√≠a de las lenguas analizadas.
    
### EXTRA:

- Imprimir la [matr√≠z de confusi√≥n](https://en.wikipedia.org/wiki/Confusion_matrix) para el etiquetador CRFs visto en clase y elaborar una conclusi√≥n sobre los resultados

## 2: Propiedades estad√≠sticas de la lengua

### Fecha de entrega: 2 de Marzo de 2025 11:59pm

1. Verificar si la ley de Zipf se cumple en un lenguaje artificial creado por ustedes.
    - *Ejemplo:* Un "lenguaje artificial" podr√≠a ser simplemente un texto donde las secuencias de caracteres fueron generadas aleatoriamente.
2. Explorar `datasets` del sitio [Hugging Face](https://huggingface.co/datasets) y elegir documentos de diferentes dominios en Espa√±ol (al menos 3). Realizar reconocimiento de entidades nombradas (NER).
    - Pueden utilizar subconjuntos de los datasets encontrados
    - Mostrar resultados del reconocimiento
    - Una distribuci√≥n de frecuencias de las etiquetas m√°s comunes en cada dominio
    - Comentarios generales del desempe√±o observado.

*Sugerencias: Spacy, CoreNLP (puede ser cualquier otra herramienta)*

## 3. Pr√°ctica: Vectores a palabras

### Fecha de entrega: 19 de Marzo de 2025 @ 11:59pm

Obtenga la matriz de co-ocurrencia para un corpus en espa√±ol y realice los siguientes calculos:
- Las probabilidades conjuntas
$$p(w_i,w_j) = \frac{c_{i,j}}{\sum_i \sum_j c_{i,j}}$$
- Las probabilidades marginales
$$p(w_i) = \sum_j p(w_i,w_j)$$
- Positive Point Wise Mutual Information (PPMI):
$$PPMI(w_i,w_j) = \max\{0, \log_2 \frac{p(w_i,w_j)}{p(w_i)p(w_j)}\}$$

**Comparaci√≥n de representaciones**

Aplica reducci√≥n de dimensionalidad (a 2D) de los vectores de la matr√≠z con PPMI y de los vectores entrenados en espa√±ol:

- Realiza un plot de 100 vectores aleatorios (que esten tanto en la matr√≠z como en los vectores entrenados)
- Compara los resultados de los plots:
    - ¬øQu√© representaci√≥n dir√≠as que captura mejor relaciones sem√°nticas?
    - Realiza un cuadro comparativo de ambos m√©todos con ventajas/desventajas

## Pr√°ctica 4: Modelos del Lenguaje Neuronales

**Fecha de entrega: 6 de abril de 2025 11:59pm**

A partir del modelo entrenado:

- Sacar los embeddings de las palabras del vocabulario

- Visualizar en 2D los embeddings de algunas palabras (quiz√° las m√°s frecuentes, excluyendo stopwords)

- Seleccione algunas palabras y verifique s√≠ realmente codifican nociones sem√°nticas, e,g, similitud sem√°ntica con similitud coseno entre dos vectores, analog√≠as por medios de operaciones de vectores

**NOTA**: Puedes entrenar el modelo replicando la ejecuci√≥n del notebook o encontrar el modelo entrenado en la [carpeta de drive](https://drive.google.com/drive/folders/1Mq-UA0ct5iTp-7h8-SxJxwyjdMHXmwO4?usp=drive_link)

### Extra (0.5 pts):

- Correr el modelo de Bengio pero aplicando una t√©cnica de subword tokenization al corpus y hacer generaci√≥n del lenguaje

- La generaci√≥n del lenguaje debe ser secuencias de palabras (no subwords)

## Pr√°ctica 5: Tech evolution. Caso *POS Tagging*

**Fecha de entrega: 13 de Abril 2025 11:59pm**

- Obten los embeddings de 100 palabras al azar del modelo RNN visto en clase
  - Pueden ser los embeddings est√°ticos o los din√°micos del modelo
- Aplica un algoritmo de clusterizaci√≥n a las palabras y plotearlas en 2D
  - Aplica algun color para los diferentes clusters
- Agrega al plot los embeddings de las etiquetas POS
  - Utiliza un marcador que las distinga claramente de las palabras
- Realiza una conclusi√≥n sobre los resultados observados

### Extra: 0.5pt

- Implementa una red *Long short-term memory units (LSTM)* para la tarea de etiquetado POS
- Reporta el accuracy y comparalo con los resultados de la RNN simple
- Realiza un comentario sobre como impacta la arquitectura LSTM sobre el resultado obtenido

## Pr√°ctica 6: *Fine-tuning en producci√≥n*

**Fecha de entrega: 11 de mayo de 2025 11:59pm**

- Selecciona un modelo pre-entrenado como base y realiza *fine-tuning* para resolver alguna tarea de NLP que te parezca reelevante
  - Procura utilizar datasets peque√±os para que sea viable
  - Recuerda las posibles tareas disponibles en HF `*For<task>`
- Desarrolla y pon en producci√≥n un prototipo del modelo
  - Incluye una URL p√∫blica donde podamos ver tu proyecto
  - Recomendamos usar framewoks de prototipado (*streamlit* o *gradio*) y el *free-tier* de *spaces* de hugging face
    - https://huggingface.co/spaces/launch
    - https://huggingface.co/docs/hub/spaces-sdks-streamlit
    - https://huggingface.co/docs/hub/spaces-sdks-gradio
- Reporta que tan bien se resolvi√≥ la tarea y que tan √∫til fue tu app
- Reporta retos y dificultades al realizar el *fine-tuning* y al poner tu modelo en producci√≥n

### Extra: 0.5pt

- Utiliza [code carbon](https://codecarbon.io/#howitwork) para reportar las emisiones de tu app

## Pr√°ctica final: Construcci√≥n de un *Retrieval-augmented Generation (RAG)* especializado

**Fecha de entrega: 25 de mayo de 2025 11:59pm**

Desarrolla en equipos de dos/tres personas una aplicaci√≥n *user-friendly* que implemente un RAG con alg√∫n LLM "ligero" local usando `ollama`

### Requerimientos

- Deber√° correr "razonablemente bien" en sus laptops
- Interface de usuaria
  - Puede ser CLI o GUI
    - Opciones GUI: [Streamlit](https://streamlit.io/), [Gradio](https://www.gradio.app/)
    - Opciones CLI: [Argparse](https://docs.python.org/3/library/argparse.html), [Click](https://click.palletsprojects.com/en/stable/)
  - La usuaria deberia poder agregar sus documentos personales en local
    - El soporte de formatos queda a su consideraci√≥n
      - CSVs, txts, pdfs o todos 
- Agrega documentaci√≥n sobre el uso y capacidades del sistema
  - Recursos sobre documentaciones perronas: https://diataxis.fr/
- Agrega una reflexi√≥n sobre las limitaciones del sistema y problemas sociales que puedan surgir de los mismos como riesgos, sesgos, protecci√≥n de datos, implicaciones √©ticas y su impacto en la diversidad social.
  - Aborda los temas que consideres m√°s reelevantes, no necesariamente todos


### Ideas de apps (elige una)

#### StudyBuddy

Aplicaci√≥n que con base en tus notas de clase y documentos relacionados te ayuda a estudiar para pasar tu examen final.

#### LegalLangSimplifier

Poder hacer queries en un conjunto de documentos legales (el diario oficial de la federaci√≥n, la constituci√≥n, reglamento de tr√°nsito, mi contrato de empleado de la UNAM) y obtener respuestas entendibles para cualquier persona sin especializaci√≥n en este lenguaje.

#### La app que quieras proponer üßôüèº‚Äç‚ôÇÔ∏è

> Deben utilizar RAG

**NOTA:** Experimenten con modelos peque√±os para la etapa de desarrollo, modifiquen los prompts y consideren las limitantes de recursos de c√≥mputo
