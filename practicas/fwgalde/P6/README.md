# PrÃ¡ctica 6: *Fine-tuning en producciÃ³n*
## Entorno de desarrollo ğŸŒ
- Ubuntu 22.04.4 LTS jammy ğŸ§
- Python 3.11.11 ğŸ
- Jupyter ğŸ““
  - IPython          : 7.34.0 âš™ï¸
  - ipykernel        : 6.17.1 ğŸš€
  - ipywidgets       : 8.1.5 ğŸ›ï¸
  - jupyter_client   : 8.6.3 ğŸ“¡
  - jupyter_core     : 5.7.2 ğŸ› ï¸
  - jupyter_server   : 2.12.5 ğŸŒ
  - jupyterlab       : 3.6.8 ğŸ–¥ï¸
  - nbclient         : 0.5.13 ğŸ¤–
  - nbconvert        : 6.4.5 ğŸ”„
  - nbformat         : 5.10.4 ğŸ“
  - notebook         : 6.5.4 ğŸ“’
  - qtconsole        : 5.6.1 ğŸ’¬
  - traitlets        : 5.7.1 ğŸ§©

## DescripciÃ³n de la aplicaciÃ³n ğŸ’¡

La aplicaciÃ³n web, desplegada en [Hugging Face Spaces](https://huggingface.co/spaces/fwgalde/dota2-toxic-detector-space), permite:

1. Ingresar un mensaje de chat de DotaÂ 2.
2. Clasificar la toxicidad en tres niveles:

   * **non-toxic**
   * **mild toxicity**
   * **toxic**
3. Mostrar las probabilidades asociadas a cada categorÃ­a mediante una interfaz sencilla basada en Gradio.

## Dependencias ğŸ“¦
Para el correcto funcionamiento del programa se necesitan las siguientes dependencias:

- numpy=1.26.4 ğŸ”¢
- scikit-learn=1.2.2 ğŸ¤–
- rich=14.0.0 ğŸ¨
- pandas=2.2.3 ğŸ¼
- transformers=4.51.1 ğŸ¤—
- codecarbon=3.0.1 ğŸŒ±
- huggingface-hub=0.30.2 â˜ï¸

Para mÃ¡s informaciÃ³n se puede consultar el documento [requirements.txt](requirements.txt) ğŸ“„


## MÃ©tricas de evaluaciÃ³n ğŸ“Š
### Modelo propio ğŸ§

Se utilizaron 638 ejemplos del conjunto de prueba para evaluar el rendimiento:

|        MÃ©trica |   Valor |
| -------------: | ------: |
| PÃ©rdida (Loss) |  1.5071 |
|   **Accuracy** | 82.13 % |
|   **F1 Macro** | 76.30 % |

**PrecisiÃ³n por clase:**

* **ClaseÂ 0 (non-toxic)**: precisionÂ 0.96, recallÂ 0.92, f1-scoreÂ 0.94 (353 muestras)
* **ClaseÂ 1 (mild toxicity)**: precisionÂ 0.63, recallÂ 0.63, f1-scoreÂ 0.63 (118 muestras)
* **ClaseÂ 2 (toxic)**: precisionÂ 0.69, recallÂ 0.76, f1-scoreÂ 0.73 (167 muestras)

Estos resultados muestran un alto desempeÃ±o en la clase mayoritaria y un rendimiento aceptable en las clases minoritarias, con oportunidades de mejora mediante tÃ©cnicas de balanceo de datos y preprocesamiento especializado.

---

*Generado con apoyo de herramientas de IA para documentaciÃ³n y formato.*

### ComparaciÃ³n con modelo baseline ğŸ”

El modelo fine-tuned original publicado por el creador del dataset usÃ³ **bert-base-uncased** y arrojÃ³ estas mÃ©tricas sobre las mismas 638 muestras de prueba:

| MÃ©trica        |  Valor |
| -------------- | -----: |
| PÃ©rdida (Loss) | 0.9516 |
| Accuracy       | 79.78% |
| F1 Macro       | 73.52% |

**PrecisiÃ³n por clase (baseline):**

* **ClaseÂ 0 (non-toxic)**: precisionÂ 0.91, recallÂ 0.91, f1-scoreÂ 0.91 (353 muestras)
* **ClaseÂ 1 (mild toxicity)**: precisionÂ 0.60, recallÂ 0.58, f1-scoreÂ 0.59 (118 muestras)
* **ClaseÂ 2 (toxic)**: precisionÂ 0.70, recallÂ 0.72, f1-scoreÂ 0.71 (167 muestras)

Nuestra versiÃ³n, basada en **roberta-base**, supera este baseline, alcanzando **82.13%** de accuracy y **76.30%** de F1 Macro, mejorando principalmente las mÃ©tricas globales y el rendimiento en las clases minoritarias.

## Conclusiones ğŸ

### Â¿ResolviÃ³ la tarea? Â¿QuÃ© tan Ãºtil fue la app?

La aplicaciÃ³n logrÃ³ cumplir el objetivo principal: detectar y clasificar la toxicidad en mensajes de chat de videojuegos (DotaÂ 2) con un alto nivel de precisiÃ³n y un F1 Macro competitivo. El flujo de trabajo de Gradio ofrece respuestas en tiempo real, facilitando su uso en moderaciÃ³n automÃ¡tica de comunidades o integraciÃ³n en bots de streaming.

### Retos y dificultades âš ï¸

* **SelecciÃ³n de dataset:** Encontrar un conjunto de datos adecuado fue el mayor obstÃ¡culo. Aunque varios datasets estaban disponibles, muchos ejemplos eran ambiguos o no cubrÃ­an bien la jerga, lo que afectÃ³ la calidad de las predicciones.
* **Prueba de modelos preentrenados:** Se evaluaron mÃºltiples backbones (DistilBERT, ALBERT), pero ninguno mejorÃ³ sustancialmente el desempeÃ±o inicial antes de llegar a RoBERTa.
* **Despliegue en producciÃ³n:** El proceso de subir el modelo a Hugging Face requiriÃ³ familiarizarse con la autenticaciÃ³n por tokens y con la estructura de repositorios (`config.json`, tokenizador, pesos), lo que generÃ³ varios errores de autorizaciÃ³n y configuraciÃ³n.
* **IntegraciÃ³n de CodeCarbon:** Las versiones de NVML de la GPU en entornos como Kaggle y Colab no soportaban las llamadas de energÃ­a total, por lo que fue necesario adaptar el tracker para medir solo CPU/RAM y garantizar un reporte sin fallos.
---

## Notas ğŸ“
- Se utilizaron LLMâ€™s ğŸ¤– para la realizaciÃ³n de documentaciÃ³n y formato del cÃ³digo.
- Toda la informaciÃ³n sobre las emisiones de mi aplicaciÃ³n se puede encontrar en el archivo [emissions.csv](emissions.csv).
- La aplicaciÃ³n para Hugginface fue realizada con el SDK de Gradio y se puede ver el diseÃ±o de la "interfaz" en el archivo [app.py](app.py).