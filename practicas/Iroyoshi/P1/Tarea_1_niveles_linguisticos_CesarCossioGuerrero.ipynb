{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "76b3a996-772a-4be8-a8eb-f1e9ae67d03e",
      "metadata": {
        "id": "76b3a996-772a-4be8-a8eb-f1e9ae67d03e"
      },
      "source": [
        "# 1. Niveles Lingüísticos\n",
        "\n",
        "### Cesar Cossio Guerrero"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tarea 1: Niveles del lenguaje\n",
        "\n",
        "### FECHA DE ENTREGA: 16 de Febrero 2025 at 11:59pm\n",
        "\n",
        "### Fonética\n",
        "\n",
        "1. Si tenemos un sistema de búsqueda que recibe una palabra ortográfica y devuelve sus transcripciones fonológicas, proponga una solución para los casos en que la palabra buscada no se encuentra en el lexicón/diccionario. *¿Cómo devolver o aproximar su transcripción fonológica?*\n",
        "  - Reutiliza el sistema de búsqueda visto en clase y mejoralo con esta funcionalidad\n",
        "\n",
        "### Morfología\n",
        "\n",
        "2. Obtenga los datos de `test` y `dev` para todas las lenguas disponibles en el Shared Task SIGMORPHON 2022 y haga lo siguiente:\n",
        "    - En un plot de 4 columnas y 2 rows muestre las siguientes distribuciones (un subplot por lengua):\n",
        "        - Plot 1: distribución de longitud de palabras\n",
        "        - Plot 2: distribución de la cuenta de morfemas\n",
        "        - Plot 3: distribución de categorias (si existe para la lengua)\n",
        "    - Realice una función que imprima por cada lengua lo siguiente:\n",
        "        - Total de palabras\n",
        "        - La longitud de palabra promedio\n",
        "        - La cuenta de morfemas promedio\n",
        "        - La categoría más común\n",
        "    - Con base en esta información elabore una conclusión lingüística sobre la morfología de las lenguas analizadas.\n",
        "    \n",
        "### EXTRA:\n",
        "\n",
        "- Imprimir la [matríz de confusión](https://en.wikipedia.org/wiki/Confusion_matrix) para el etiquetador CRFs visto en clase y elaborar una conclusión sobre los resultados"
      ],
      "metadata": {
        "id": "qvtmXNPDki24"
      },
      "id": "qvtmXNPDki24"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ejercicio 1 Fonética**"
      ],
      "metadata": {
        "id": "PX3N6ZktYwaF"
      },
      "id": "PX3N6ZktYwaF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Cómo se elige una representación fonológica parecida a una palabra que no está en el vocabulario? Con la similitud de Jaro-Winkler se encuentra la palabra más parecida en la base de datos y luego se usa la misma función que vimos en clase para encontrar su representación fonológica. La cual es la más parecida a la palabra de entrada. Para ello cree una función que se muestra a continuación"
      ],
      "metadata": {
        "id": "ASm2rDuhWQGQ"
      },
      "id": "ASm2rDuhWQGQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Funciones Necesarias para el ejercicio 1**"
      ],
      "metadata": {
        "id": "F3tSGDwbiWvA"
      },
      "id": "F3tSGDwbiWvA"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jellyfish\n",
        "import jellyfish\n",
        "import http\n",
        "import requests as r\n",
        "from pprint import pprint as pp\n",
        "IPA_URL = \"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/{lang}.txt\""
      ],
      "metadata": {
        "id": "PCBkNFZTTLwA"
      },
      "id": "PCBkNFZTTLwA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_ipa_corpus(iso_lang: str) -> str:\n",
        "    \"\"\"Get ipa-dict file from Github\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    iso_lang:\n",
        "        Language as iso code\n",
        "\n",
        "    Results:\n",
        "    --------\n",
        "    dict:\n",
        "        Dictionary with words as keys and phonetic representation\n",
        "        as values for a given lang code\n",
        "    \"\"\"\n",
        "    print(f\"Downloading {iso_lang}\", end=\"::\")\n",
        "    response = r.get(IPA_URL.format(lang=iso_lang))\n",
        "    status_code = response.status_code\n",
        "    print(f\"status={status_code}\")\n",
        "    if status_code != http.HTTPStatus.OK:\n",
        "        print(f\"ERROR on {iso_lang} :(\")\n",
        "        return \"\"\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "p481kBDvhz9p"
      },
      "id": "p481kBDvhz9p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_response(response: str) -> dict:\n",
        "    \"\"\"Parse text response from ipa-dict to python dict\n",
        "\n",
        "    Each row have the format:\n",
        "    [WORD][TAB]/[IPA]/(, /[IPA]/)?\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    response: str\n",
        "        ipa-dict raw text\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict:\n",
        "        A dictionary with the word as key and the phonetic\n",
        "        representations as value\n",
        "    \"\"\"\n",
        "    ipa_list = response.rstrip().split(\"\\n\")\n",
        "    result = {}\n",
        "    for item in ipa_list:\n",
        "        if item == '':\n",
        "            continue\n",
        "        item_list = item.split(\"\\t\")\n",
        "        result[item_list[0]] = item_list[1]\n",
        "    return result\n",
        "\n",
        "es_mx_ipa = parse_response(download_ipa_corpus(\"es_MX\"))"
      ],
      "metadata": {
        "id": "EyoykjU1haZZ"
      },
      "id": "EyoykjU1haZZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ipa_transcriptions(word: str, dataset: dict) -> list[str]:\n",
        "    \"\"\"Search for a word in an IPA phonetics dict\n",
        "\n",
        "    Given a word this function return the IPA transcriptions\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    word: str\n",
        "        A word to search in the dataset\n",
        "    dataset: dict\n",
        "        A dataset for a given language code\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[str]:\n",
        "        List with posible transcriptions if any,\n",
        "        else an empty list\n",
        "    \"\"\"\n",
        "    return dataset.get(word.lower(), \"\").split(\", \")"
      ],
      "metadata": {
        "id": "htG02-bjhOdQ"
      },
      "id": "htG02-bjhOdQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_similar_word(word, dataset):\n",
        "    \"\"\"\n",
        "    Encuentra la palabra más parecida en el dataset a la palabra de entrada usando la similitud de Jaro-Winkler\n",
        "\n",
        "    Parámetros:\n",
        "        word: La palabra de entrada para comparar\n",
        "        dataset: Un diccionario cuyas llaves son las palabras del vocabularios y sus valores son las\n",
        "                representacions fonéticas.\n",
        "\n",
        "    Regresa:\n",
        "        La palabra que más se parece del dataset a la palabra de entrada\n",
        "        según la similitud de Jaro Winkler.\n",
        "    \"\"\"\n",
        "\n",
        "    max_similarity = 0\n",
        "    most_similar_word = word\n",
        "    for dataset_word in dataset:\n",
        "        similarity = jellyfish.jaro_similarity(word, dataset_word)\n",
        "        if similarity > max_similarity:\n",
        "            max_similarity = similarity\n",
        "            most_similar_word = dataset_word\n",
        "\n",
        "    print('La palabra que buscas no está.\\nLa palabra más parecida es: \\033[1m ',\n",
        "          most_similar_word,'\\033[0m \\nY la representación fonológica es: ')\n",
        "    return most_similar_word\n",
        "\n",
        "\n",
        "def improved_get_ipa_transcriptions(word, dataset):\n",
        "    \"\"\"\n",
        "    Searches for a word in an IPA phonetics dict.\n",
        "    If the word is not in the dataset, then the most similar one is used instead using\n",
        "    Jaro Winkler similarity.\n",
        "\n",
        "    Args:\n",
        "        word: The word to search for.\n",
        "        dataset: The phonetic dictionary.\n",
        "\n",
        "    Returns:\n",
        "        A list of IPA transcriptions. If the word is not found, it tries to find the most similar word\n",
        "        in the dataset and return its transcriptions.\n",
        "    \"\"\"\n",
        "    transcriptions = dataset.get(word.lower(), [])\n",
        "    if transcriptions:\n",
        "        return transcriptions.split(\", \")\n",
        "\n",
        "    # Word not found, try to find similar word\n",
        "    most_similar = find_most_similar_word(word, dataset)\n",
        "    print('\\033[1m ',dataset.get(most_similar.lower(), \"\").split(\", \"),'\\033[0m')\n",
        "    return\n",
        "\n"
      ],
      "metadata": {
        "id": "YqtjlTq7P51X"
      },
      "id": "YqtjlTq7P51X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Solución**\n",
        "### Se hace la prueba sobre la palabra **mayonesa** con una alteración a **mayotesa**. En el primer campo la lista sale vacía. Usnado la función mejorada, el resultado es la representación fonológica de mayonesa\n"
      ],
      "metadata": {
        "id": "tjK4lKOFV1xg"
      },
      "id": "tjK4lKOFV1xg"
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipa_transcriptions(\"mayotesa\", es_mx_ipa)"
      ],
      "metadata": {
        "id": "Jizr2QDRV08Z"
      },
      "id": "Jizr2QDRV08Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "improved_get_ipa_transcriptions(\"mayotesa\", es_mx_ipa)"
      ],
      "metadata": {
        "id": "955CrkQpTwEY"
      },
      "id": "955CrkQpTwEY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Funciones y librerías necesarias para el ejercicio 2**"
      ],
      "metadata": {
        "id": "sqiTh3l4i-BQ"
      },
      "id": "sqiTh3l4i-BQ"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "LANGS = {\n",
        "    \"ces\": \"Czech\",\n",
        "    \"eng\": \"English\",\n",
        "    \"fra\": \"French\",\n",
        "    \"hun\": \"Hungarian\",\n",
        "    \"spa\": \"Spanish\",\n",
        "    \"ita\": \"Italian\",\n",
        "    \"lat\": \"Latin\",\n",
        "    \"rus\": \"Russian\",\n",
        "}"
      ],
      "metadata": {
        "id": "KnrAF9Zei9pR"
      },
      "id": "KnrAF9Zei9pR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ejercicio 2: Morfología**\n",
        "\n",
        "## A continuación se muestran las gráficas de las distribuciones que se piden. Estas generadas por unas funciones que se cargan a continuación\n"
      ],
      "metadata": {
        "id": "pc7rBB_iYLHR"
      },
      "id": "pc7rBB_iYLHR"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_track_files(lang: str, track: str = \"word\") -> list[str]:\n",
        "    \"\"\"Genera una lista de nombres de archivo del shared task\n",
        "\n",
        "    Con base en el idioma y el track obtiene el nombre de los archivos\n",
        "    para con información reelevante para hacer análisis estadístico.\n",
        "    Esto es archivos .test y .dev\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    lang : str\n",
        "        Idioma para el cual se generarán los nombres de archivo.\n",
        "    track : str, optional\n",
        "        Track del shared task de donde vienen los datos (por defecto es \"word\").\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    list[str]\n",
        "        Una lista de nombres de archivo generados para el idioma y la pista especificados.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        f\"{lang}.{track}.test.gold\",\n",
        "        f\"{lang}.{track}.dev\",\n",
        "    ]\n",
        "\n",
        "\n",
        "def get_raw_corpus(files: list) -> list:\n",
        "    \"\"\"Descarga y concatena los datos de los archivos tsv desde una URL base.\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    files : list\n",
        "        Lista de nombres de archivos (sin extensión) que se descargarán\n",
        "        y concatenarán.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    list\n",
        "        Una lista que contiene los contenidos descargados y concatenados\n",
        "        de los archivos tsv.\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for file in files:\n",
        "        print(f\"Downloading {file}.tsv\", end=\" \")\n",
        "        response = r.get(f\"https://raw.githubusercontent.com/sigmorphon/2022SegmentationST/main/data/{file}.tsv\")\n",
        "        print(f\"status={response.status_code}\")\n",
        "        lines = response.text.split(\"\\n\")\n",
        "        result.extend(lines[:-1])\n",
        "    return result\n",
        "\n",
        "def raw_corpus_to_dataframe(corpus_list: list, lang: str) -> pd.DataFrame:\n",
        "    \"\"\"Convierte una lista de datos de corpus en un DataFrame\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    corpus_list : list\n",
        "        Lista de líneas del corpus a convertir en DataFrame.\n",
        "    lang : str\n",
        "        Idioma al que pertenecen los datos del corpus.\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Un DataFrame de pandas que contiene los datos del corpus procesados.\n",
        "    \"\"\"\n",
        "    data_list = []\n",
        "    for line in corpus_list:\n",
        "        try:\n",
        "            word, tagged_data, category = line.split(\"\\t\")\n",
        "        except ValueError:\n",
        "            # Caso donde no existe la categoria\n",
        "            word, tagged_data = line.split(\"\\t\")\n",
        "            category = \"NOT_FOUND\"\n",
        "        morphemes = tagged_data.split()\n",
        "        data_list.append({\"words\": word, \"morph\": morphemes, \"category\": category, \"lang\": lang})\n",
        "    df = pd.DataFrame(data_list)\n",
        "    df[\"word_len\"] = df[\"words\"].apply(lambda x: len(x))\n",
        "    df[\"morph_count\"] = df[\"morph\"].apply(lambda x: len(x))\n",
        "    return df"
      ],
      "metadata": {
        "id": "5Wv8E1-TjphB"
      },
      "id": "5Wv8E1-TjphB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Morphology_DataFrames(lang_codes):\n",
        "\n",
        "    \"\"\"\n",
        "    Una función que carga todos la información de los lenguajes\n",
        "    en un diccionario de dataframes cuya llave es el nombre\n",
        "    del lenguaje y el valor es el Dataframe correspondiente\n",
        "\n",
        "    Parámetros:\n",
        "        lang_codes: Los códigos de los lenguajes\n",
        "    \"\"\"\n",
        "\n",
        "    DF={}\n",
        "    for i, lang_code in enumerate(lang_codes):\n",
        "        files = get_track_files(lang_code)\n",
        "        raw_data = get_raw_corpus(files)\n",
        "        DF[lang_code] = raw_corpus_to_dataframe(raw_data, lang=lang_code)\n",
        "    return DF\n",
        "\n",
        "LF = Morphology_DataFrames(list(LANGS.keys()))"
      ],
      "metadata": {
        "id": "p5mEJWiJFol3"
      },
      "id": "p5mEJWiJFol3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_morphology_distributions(lang_codes,dfs,Column):\n",
        "\n",
        "    \"\"\"\n",
        "    Una función que grafica para cada lenguaje la distribución\n",
        "    correspondiente a la Columna Dada\n",
        "\n",
        "    Parámetros:\n",
        "        lang_codes: Los códigos de los lenguajes\n",
        "        dfs: Es un diccionario que contiene dataframes de los morfemas de los lenguajes\n",
        "        Column: es la característica de la cual se obtendrá la distribución\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "    axes = axes.flatten()\n",
        "    for i, lang_code in enumerate(lang_codes):\n",
        "        counts = dfs[lang_code][Column].value_counts().head(30)\n",
        "        axes[i].bar(counts.index, counts.values)\n",
        "        axes[i].set_xlabel(Column)\n",
        "        axes[i].set_ylabel('Frequency')\n",
        "        axes[i].set_title(f'{Column} Frequency Graph for {LANGS[lang_code]}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KJGJRRUiECuI"
      },
      "id": "KJGJRRUiECuI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_morphology_distributions(list(LANGS.keys()), LF, 'word_len')"
      ],
      "metadata": {
        "id": "j_ZkzfMnKfGS"
      },
      "id": "j_ZkzfMnKfGS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_morphology_distributions(list(LANGS.keys()), LF, 'category')"
      ],
      "metadata": {
        "id": "7Rswvi3VKf05"
      },
      "id": "7Rswvi3VKf05",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_morphology_distributions(list(LANGS.keys()), LF, 'morph_count')"
      ],
      "metadata": {
        "id": "S2VfN5__KfkC"
      },
      "id": "S2VfN5__KfkC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A continuación se muestran todas las Estadísticas que se piden en un dataframe**\n"
      ],
      "metadata": {
        "id": "SIgKzQpUU5hM"
      },
      "id": "SIgKzQpUU5hM"
    },
    {
      "cell_type": "code",
      "source": [
        "def Medidas_Morfologicas(lang, dfs):\n",
        "\n",
        "    \"\"\"\n",
        "    Una función que genera estadísticas de los lenguajes\n",
        "\n",
        "    Parámetros:\n",
        "        lang_codes: Los códigos de los lenguajes\n",
        "        dfs: Es un diccionario que contiene dataframes\n",
        "        con información acerca de los morfemas de los lenguajes.\n",
        "    \"\"\"\n",
        "\n",
        "    lf = pd.DataFrame(index=list(LANGS.values()),\n",
        "                      columns=['Total de palabras', 'Longuitud de Palabras Promedio',\n",
        "                              'Promedio de Cuenta de Morfemas', 'La categoría más común'])\n",
        "\n",
        "    for lang_code_k,lang_code_v  in lang.items():\n",
        "        df = dfs[lang_code_k]\n",
        "        lf.loc[lang_code_v,'Total de palabras'] = len(df[\"words\"].unique())\n",
        "        lf.loc[lang_code_v,'Longuitud de Palabras Promedio'] = df[\"word_len\"].mean()\n",
        "        lf.loc[lang_code_v,'Promedio de Cuenta de Morfemas'] = df[\"morph_count\"].mean()\n",
        "        lf.loc[lang_code_v,'La categoría más común'] = df[\"category\"].mode()[0]\n",
        "\n",
        "    return lf\n",
        "\n",
        "Medidas_Morfologicas(LANGS, LF)\n"
      ],
      "metadata": {
        "id": "ftgcVuEnOqlo"
      },
      "id": "ftgcVuEnOqlo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lo que más me sorprende es que en general  los lenguajes aquí estudiados tienen un comportamiento bastante similar a pesar de pertenecer a ramas lingüísticas muy diferentes. Me soprendió mucho observar que en el fondo comparten muchas similitudes aunque parezcan, se escriban y suenen muy diferentes. Es decir, tienen morfologías y fonologías distintas, pero en el fondo parece que siguieran ciertas reglas."
      ],
      "metadata": {
        "id": "yTE8kHdWY8E1"
      },
      "id": "yTE8kHdWY8E1"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRBjwqmhZkYb"
      },
      "id": "mRBjwqmhZkYb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "jupytext": {
      "formats": "ipynb,auto:light"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}